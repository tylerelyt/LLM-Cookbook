#!/usr/bin/env python3
"""
Failure Learner - ä»å¤±è´¥ä¸­å­¦ä¹ çš„æ ¸å¿ƒé€»è¾‘

å®ç°æ™ºèƒ½çš„å¤±è´¥å­¦ä¹ æœºåˆ¶ï¼Œè®©Agentä»é”™è¯¯ä¸­è·å¾—æ´å¯Ÿå¹¶æ”¹è¿›è¡Œä¸ºã€‚
"""

import json
import math
import argparse
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
import numpy as np

from error_tracker import ErrorTracker, ErrorRecord, ActionRecord, ErrorType


@dataclass 
class LearningInsight:
    """å­¦ä¹ æ´å¯Ÿ"""
    insight_type: str
    description: str
    confidence: float
    supporting_evidence: List[str]
    actionable_advice: str
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
    
    def to_dict(self) -> Dict:
        data = asdict(self)
        data['created_at'] = self.created_at.isoformat()
        return data


@dataclass
class BehaviorPattern:
    """è¡Œä¸ºæ¨¡å¼"""
    pattern_id: str
    pattern_type: str  # success, failure, mixed
    trigger_conditions: Dict[str, Any]
    observed_outcomes: List[str]
    frequency: int
    last_observed: datetime
    confidence_score: float


class FailureLearner:
    """å¤±è´¥å­¦ä¹ å™¨ - ä»é”™è¯¯ä¸­æå–æ´å¯Ÿå’Œæ¨¡å¼"""
    
    def __init__(self, error_tracker: ErrorTracker):
        self.error_tracker = error_tracker
        self.learned_insights: List[LearningInsight] = []
        self.behavior_patterns: Dict[str, BehaviorPattern] = {}
        self.knowledge_base = self._initialize_knowledge_base()
        
        print("ğŸ§  Failure Learner initialized")
    
    def _initialize_knowledge_base(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        return {
            "error_prevention_rules": [
                "Always validate parameters before API calls",
                "Check file existence before read operations", 
                "Implement exponential backoff for rate-limited APIs",
                "Use circuit breakers for frequently failing operations",
                "Validate input ranges for mathematical operations"
            ],
            "recovery_strategies": {
                "file_operations": ["check_permissions", "try_alternative_path", "create_directory"],
                "api_calls": ["retry_with_backoff", "use_cached_data", "fallback_endpoint"],
                "calculations": ["validate_inputs", "use_safe_defaults", "approximate_result"],
                "network": ["check_connectivity", "use_offline_mode", "retry_different_endpoint"]
            },
            "success_indicators": [
                "operation_completed_without_error",
                "result_within_expected_range", 
                "response_time_acceptable",
                "resource_usage_normal"
            ]
        }
    
    def analyze_failure_patterns(self) -> List[LearningInsight]:
        """åˆ†æå¤±è´¥æ¨¡å¼å¹¶ç”Ÿæˆå­¦ä¹ æ´å¯Ÿ"""
        print("ğŸ” Analyzing failure patterns...")
        
        insights = []
        
        # 1. åˆ†æé¢‘ç¹å¤±è´¥çš„æ“ä½œ
        insights.extend(self._analyze_frequent_failures())
        
        # 2. åˆ†ææ—¶é—´ç›¸å…³çš„å¤±è´¥æ¨¡å¼
        insights.extend(self._analyze_temporal_patterns())
        
        # 3. åˆ†æå‚æ•°ç›¸å…³çš„å¤±è´¥æ¨¡å¼
        insights.extend(self._analyze_parameter_patterns())
        
        # 4. åˆ†ææ¢å¤ç­–ç•¥çš„æœ‰æ•ˆæ€§
        insights.extend(self._analyze_recovery_effectiveness())
        
        # 5. åˆ†æé”™è¯¯ä¼ æ’­é“¾
        insights.extend(self._analyze_error_chains())
        
        self.learned_insights.extend(insights)
        return insights
    
    def _analyze_frequent_failures(self) -> List[LearningInsight]:
        """åˆ†æé¢‘ç¹å¤±è´¥çš„æ“ä½œ"""
        insights = []
        
        # ç»Ÿè®¡æ¯ç§å·¥å…·çš„å¤±è´¥æ¬¡æ•°
        tool_failures = defaultdict(int)
        tool_errors = defaultdict(list)
        
        for error in self.error_tracker.error_history:
            tool = error.action.tool
            tool_failures[tool] += 1
            tool_errors[tool].append(error)
        
        # è¯†åˆ«é«˜å¤±è´¥ç‡çš„å·¥å…·
        total_errors = len(self.error_tracker.error_history)
        for tool, failure_count in tool_failures.items():
            failure_rate = failure_count / total_errors
            
            if failure_rate > 0.3 and failure_count >= 3:  # 30%ä»¥ä¸Šå¤±è´¥ç‡ä¸”è‡³å°‘3æ¬¡å¤±è´¥
                # åˆ†æå¤±è´¥åŸå› 
                error_codes = Counter(err.error_code for err in tool_errors[tool])
                most_common_error = error_codes.most_common(1)[0]
                
                insight = LearningInsight(
                    insight_type="frequent_failure",
                    description=f"Tool '{tool}' has high failure rate ({failure_rate:.1%})",
                    confidence=min(0.9, failure_rate * 2),  # åŸºäºå¤±è´¥ç‡è®¡ç®—ç½®ä¿¡åº¦
                    supporting_evidence=[
                        f"Failed {failure_count} out of {total_errors} total operations",
                        f"Most common error: {most_common_error[0]} ({most_common_error[1]} times)",
                        f"Error types: {list(error_codes.keys())}"
                    ],
                    actionable_advice=f"Consider implementing pre-validation for {tool} operations or using alternative tools"
                )
                insights.append(insight)
        
        return insights
    
    def _analyze_temporal_patterns(self) -> List[LearningInsight]:
        """åˆ†ææ—¶é—´ç›¸å…³çš„å¤±è´¥æ¨¡å¼"""
        insights = []
        
        if len(self.error_tracker.error_history) < 5:
            return insights
        
        # åˆ†æé”™è¯¯å‘ç”Ÿçš„æ—¶é—´é—´éš”
        timestamps = [err.timestamp for err in self.error_tracker.error_history]
        timestamps.sort()
        
        intervals = []
        for i in range(1, len(timestamps)):
            interval = (timestamps[i] - timestamps[i-1]).total_seconds()
            intervals.append(interval)
        
        if intervals:
            avg_interval = np.mean(intervals)
            std_interval = np.std(intervals)
            
            # æ£€æµ‹é”™è¯¯çˆ†å‘æ¨¡å¼ï¼ˆçŸ­æ—¶é—´å†…å¤šæ¬¡é”™è¯¯ï¼‰
            burst_threshold = avg_interval - std_interval
            burst_errors = sum(1 for interval in intervals if interval < burst_threshold)
            
            if burst_errors > len(intervals) * 0.3:  # 30%ä»¥ä¸Šæ˜¯çªå‘é”™è¯¯
                insight = LearningInsight(
                    insight_type="temporal_burst",
                    description="Detected error burst pattern - multiple failures in short time windows",
                    confidence=0.8,
                    supporting_evidence=[
                        f"Average error interval: {avg_interval:.1f} seconds",
                        f"Burst errors detected: {burst_errors}/{len(intervals)}",
                        f"Burst threshold: {burst_threshold:.1f} seconds"
                    ],
                    actionable_advice="Implement circuit breaker pattern to prevent cascading failures"
                )
                insights.append(insight)
        
        return insights
    
    def _analyze_parameter_patterns(self) -> List[LearningInsight]:
        """åˆ†æå‚æ•°ç›¸å…³çš„å¤±è´¥æ¨¡å¼"""
        insights = []
        
        # åˆ†æå¯¼è‡´é”™è¯¯çš„å‚æ•°æ¨¡å¼
        parameter_failures = defaultdict(list)
        
        for error in self.error_tracker.error_history:
            tool = error.action.tool
            params = error.action.parameters
            
            for param_name, param_value in params.items():
                key = f"{tool}.{param_name}"
                parameter_failures[key].append({
                    'value': param_value,
                    'error_code': error.error_code,
                    'error_type': error.error_type.value
                })
        
        # è¯†åˆ«é—®é¢˜å‚æ•°
        for param_key, failures in parameter_failures.items():
            if len(failures) >= 3:  # è‡³å°‘3æ¬¡å¤±è´¥
                values = [f['value'] for f in failures]
                error_codes = [f['error_code'] for f in failures]
                
                # æ£€æµ‹ç‰¹å®šå€¼æ¨¡å¼
                value_counter = Counter(str(v) for v in values)
                most_common_value = value_counter.most_common(1)[0]
                
                if most_common_value[1] >= 2:  # åŒä¸€å€¼å¯¼è‡´å¤šæ¬¡å¤±è´¥
                    insight = LearningInsight(
                        insight_type="problematic_parameter",
                        description=f"Parameter '{param_key}' frequently causes failures",
                        confidence=0.7,
                        supporting_evidence=[
                            f"Failed {len(failures)} times",
                            f"Problematic value: '{most_common_value[0]}' ({most_common_value[1]} times)",
                            f"Error codes: {list(set(error_codes))}"
                        ],
                        actionable_advice=f"Add validation for parameter '{param_key}' before use"
                    )
                    insights.append(insight)
        
        return insights
    
    def _analyze_recovery_effectiveness(self) -> List[LearningInsight]:
        """åˆ†ææ¢å¤ç­–ç•¥çš„æœ‰æ•ˆæ€§"""
        insights = []
        
        # ç»Ÿè®¡æ¢å¤ç­–ç•¥çš„æˆåŠŸç‡
        strategy_stats = defaultdict(lambda: {'total': 0, 'success': 0})
        
        for error in self.error_tracker.error_history:
            for attempt in error.recovery_attempts:
                strategy = attempt['strategy']
                strategy_stats[strategy]['total'] += 1
                if attempt['success']:
                    strategy_stats[strategy]['success'] += 1
        
        # è¯†åˆ«ä½æ•ˆçš„æ¢å¤ç­–ç•¥
        for strategy, stats in strategy_stats.items():
            if stats['total'] >= 3:  # è‡³å°‘ä½¿ç”¨3æ¬¡
                success_rate = stats['success'] / stats['total']
                
                if success_rate < 0.3:  # æˆåŠŸç‡ä½äº30%
                    insight = LearningInsight(
                        insight_type="ineffective_recovery",
                        description=f"Recovery strategy '{strategy}' has low success rate",
                        confidence=0.8,
                        supporting_evidence=[
                            f"Success rate: {success_rate:.1%}",
                            f"Successful attempts: {stats['success']}/{stats['total']}"
                        ],
                        actionable_advice=f"Consider alternative recovery strategies for '{strategy}' scenarios"
                    )
                    insights.append(insight)
                
                elif success_rate > 0.8:  # æˆåŠŸç‡é«˜äº80%
                    insight = LearningInsight(
                        insight_type="effective_recovery",
                        description=f"Recovery strategy '{strategy}' is highly effective",
                        confidence=0.9,
                        supporting_evidence=[
                            f"Success rate: {success_rate:.1%}",
                            f"Successful attempts: {stats['success']}/{stats['total']}"
                        ],
                        actionable_advice=f"Prioritize '{strategy}' strategy for similar error types"
                    )
                    insights.append(insight)
        
        return insights
    
    def _analyze_error_chains(self) -> List[LearningInsight]:
        """åˆ†æé”™è¯¯ä¼ æ’­é“¾"""
        insights = []
        
        # æŒ‰æ—¶é—´æ’åºé”™è¯¯
        sorted_errors = sorted(self.error_tracker.error_history, key=lambda x: x.timestamp)
        
        # æ£€æµ‹é”™è¯¯é“¾ï¼ˆçŸ­æ—¶é—´å†…è¿ç»­å‘ç”Ÿçš„ç›¸å…³é”™è¯¯ï¼‰
        chain_threshold = timedelta(minutes=5)  # 5åˆ†é’Ÿå†…çš„é”™è¯¯è®¤ä¸ºæ˜¯ç›¸å…³çš„
        error_chains = []
        current_chain = []
        
        for i, error in enumerate(sorted_errors):
            if not current_chain:
                current_chain = [error]
            else:
                last_error = current_chain[-1]
                time_diff = error.timestamp - last_error.timestamp
                
                if time_diff <= chain_threshold:
                    current_chain.append(error)
                else:
                    if len(current_chain) >= 3:  # è‡³å°‘3ä¸ªé”™è¯¯å½¢æˆé“¾
                        error_chains.append(current_chain)
                    current_chain = [error]
        
        # æ·»åŠ æœ€åä¸€ä¸ªé“¾
        if len(current_chain) >= 3:
            error_chains.append(current_chain)
        
        # åˆ†æé”™è¯¯é“¾
        for chain in error_chains:
            tools_in_chain = [err.action.tool for err in chain]
            error_types_in_chain = [err.error_type.value for err in chain]
            
            insight = LearningInsight(
                insight_type="error_chain",
                description=f"Detected error chain with {len(chain)} consecutive failures",
                confidence=0.7,
                supporting_evidence=[
                    f"Duration: {(chain[-1].timestamp - chain[0].timestamp).total_seconds():.1f} seconds",
                    f"Tools involved: {list(set(tools_in_chain))}",
                    f"Error types: {list(set(error_types_in_chain))}"
                ],
                actionable_advice="Implement early failure detection to prevent error cascades"
            )
            insights.append(insight)
        
        return insights
    
    def generate_behavior_recommendations(self) -> List[str]:
        """åŸºäºå­¦ä¹ æ´å¯Ÿç”Ÿæˆè¡Œä¸ºå»ºè®®"""
        recommendations = []
        
        # åŸºäºæ´å¯Ÿç”Ÿæˆå»ºè®®
        for insight in self.learned_insights:
            if insight.insight_type == "frequent_failure":
                recommendations.append(f"ğŸ”§ {insight.actionable_advice}")
            elif insight.insight_type == "temporal_burst":
                recommendations.append(f"â±ï¸  {insight.actionable_advice}")
            elif insight.insight_type == "problematic_parameter":
                recommendations.append(f"ğŸ” {insight.actionable_advice}")
            elif insight.insight_type == "ineffective_recovery":
                recommendations.append(f"ğŸ”„ {insight.actionable_advice}")
            elif insight.insight_type == "error_chain":
                recommendations.append(f"ğŸš¨ {insight.actionable_advice}")
        
        # æ·»åŠ é€šç”¨å»ºè®®
        if not recommendations:
            recommendations.extend([
                "ğŸ”§ Implement comprehensive input validation",
                "â±ï¸  Add timeout handling for all external operations",
                "ğŸ”„ Use exponential backoff for retry operations",
                "ğŸš¨ Implement health checks for critical dependencies"
            ])
        
        return recommendations
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ æ€»ç»“"""
        insight_types = Counter(insight.insight_type for insight in self.learned_insights)
        
        high_confidence_insights = [
            insight for insight in self.learned_insights 
            if insight.confidence > 0.8
        ]
        
        return {
            "total_insights": len(self.learned_insights),
            "insight_breakdown": dict(insight_types),
            "high_confidence_insights": len(high_confidence_insights),
            "average_confidence": np.mean([i.confidence for i in self.learned_insights]) if self.learned_insights else 0,
            "learning_categories": list(insight_types.keys()),
            "recommendations_count": len(self.generate_behavior_recommendations())
        }
    
    def save_insights(self, filepath: str = "learning_insights.json"):
        """ä¿å­˜å­¦ä¹ æ´å¯Ÿ"""
        data = {
            "insights": [insight.to_dict() for insight in self.learned_insights],
            "summary": self.get_learning_summary(),
            "generated_at": datetime.now().isoformat()
        }
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ Learning insights saved to {filepath}")
        except Exception as e:
            print(f"âŒ Failed to save insights: {e}")


def run_learning_analysis():
    """è¿è¡Œå­¦ä¹ åˆ†æ"""
    print("ğŸ§  Failure Learning Analysis")
    print("=" * 40)
    
    # åŠ è½½é”™è¯¯æ•°æ®
    tracker = ErrorTracker("demo_error_history.json")
    
    if not tracker.error_history:
        print("âŒ No error history found. Please run error_tracker.py --create-demo first.")
        return
    
    # åˆ›å»ºå­¦ä¹ å™¨
    learner = FailureLearner(tracker)
    
    # åˆ†æå¤±è´¥æ¨¡å¼
    insights = learner.analyze_failure_patterns()
    
    print(f"\nğŸ“Š Learning Analysis Results:")
    print(f"   Analyzed {len(tracker.error_history)} errors")
    print(f"   Generated {len(insights)} insights")
    
    # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤ºæ´å¯Ÿ
    insight_groups = defaultdict(list)
    for insight in insights:
        insight_groups[insight.insight_type].append(insight)
    
    print(f"\nğŸ” Discovered Insights:")
    for insight_type, group_insights in insight_groups.items():
        print(f"\n   ğŸ“‹ {insight_type.replace('_', ' ').title()}:")
        for insight in group_insights:
            print(f"      â€¢ {insight.description}")
            print(f"        Confidence: {insight.confidence:.1%}")
            print(f"        Advice: {insight.actionable_advice}")
    
    # ç”Ÿæˆè¡Œä¸ºå»ºè®®
    recommendations = learner.generate_behavior_recommendations()
    print(f"\nğŸ’¡ Behavior Recommendations:")
    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. {rec}")
    
    # ä¿å­˜ç»“æœ
    learner.save_insights()
    
    # æ˜¾ç¤ºå­¦ä¹ æ€»ç»“
    summary = learner.get_learning_summary()
    print(f"\nğŸ“ˆ Learning Summary:")
    for key, value in summary.items():
        print(f"   {key.replace('_', ' ').title()}: {value}")
    
    return learner


def run_benchmark_test():
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    print("ğŸ† Failure Learning Benchmark Test")
    print("=" * 40)
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„é”™è¯¯è·Ÿè¸ªå™¨
    tracker = ErrorTracker("benchmark_error_history.json")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_scenarios = [
        # é‡å¤çš„æ–‡ä»¶é”™è¯¯
        *[{"tool": "file_read", "error_code": "FileNotFoundError", "error_type": ErrorType.ENVIRONMENT} for _ in range(5)],
        # APIé™é€Ÿé”™è¯¯
        *[{"tool": "api_call", "error_code": "RateLimitExceeded", "error_type": ErrorType.ENVIRONMENT} for _ in range(4)],
        # å‚æ•°é”™è¯¯
        *[{"tool": "calculator", "error_code": "ValueError", "error_type": ErrorType.LOGIC} for _ in range(3)],
        # è¶…æ—¶é”™è¯¯
        *[{"tool": "web_request", "error_code": "TimeoutError", "error_type": ErrorType.TIMEOUT} for _ in range(3)]
    ]
    
    print(f"ğŸ”„ Generating {len(test_scenarios)} test errors...")
    
    for i, scenario in enumerate(test_scenarios):
        action = ActionRecord(
            tool=scenario["tool"],
            parameters={"test_param": f"test_value_{i}"}
        )
        
        tracker.track_error(
            error_type=scenario["error_type"],
            error_code=scenario["error_code"],
            message=f"Test error {i+1}",
            action=action,
            context={"test_id": i, "scenario": scenario["tool"]}
        )
    
    # è¿è¡Œå­¦ä¹ åˆ†æ
    learner = FailureLearner(tracker)
    insights = learner.analyze_failure_patterns()
    
    # è¯„ä¼°ç»“æœ
    expected_insights = {
        "frequent_failure": 2,  # file_read å’Œ api_call åº”è¯¥è¢«è¯†åˆ«ä¸ºé¢‘ç¹å¤±è´¥
        "problematic_parameter": 0,  # å‚æ•°éƒ½ä¸åŒï¼Œä¸åº”è¯¥æ£€æµ‹åˆ°æ¨¡å¼
        "temporal_burst": 1   # å¯èƒ½æ£€æµ‹åˆ°çªå‘æ¨¡å¼
    }
    
    actual_insights = Counter(insight.insight_type for insight in insights)
    
    print(f"\nğŸ“Š Benchmark Results:")
    print(f"   Total insights generated: {len(insights)}")
    
    score = 0
    total_tests = len(expected_insights)
    
    for insight_type, expected_count in expected_insights.items():
        actual_count = actual_insights.get(insight_type, 0)
        test_passed = actual_count >= expected_count
        score += 1 if test_passed else 0
        
        status = "âœ… PASS" if test_passed else "âŒ FAIL"
        print(f"   {status} {insight_type}: Expected â‰¥{expected_count}, Got {actual_count}")
    
    final_score = score / total_tests
    print(f"\nğŸ¯ Overall Score: {final_score:.1%} ({score}/{total_tests} tests passed)")
    
    # æ¸…ç†æµ‹è¯•æ•°æ®
    import os
    try:
        os.remove("benchmark_error_history.json")
        print("ğŸ—‘ï¸  Benchmark test data cleaned up")
    except:
        pass
    
    return final_score


def main():
    parser = argparse.ArgumentParser(description="Failure Learner Demo")
    parser.add_argument("--analyze", action="store_true", help="Run learning analysis on existing data")
    parser.add_argument("--benchmark", action="store_true", help="Run benchmark test")
    parser.add_argument("--full-demo", action="store_true", help="Run full demo with analysis")
    
    args = parser.parse_args()
    
    if args.benchmark:
        score = run_benchmark_test()
        return
    
    if args.analyze:
        learner = run_learning_analysis()
        return
    
    if args.full_demo or not any(vars(args).values()):
        # é»˜è®¤è¿è¡Œå®Œæ•´æ¼”ç¤º
        print("ğŸ§  Failure Learning System Demo")
        print("=" * 40)
        print("\nğŸ’¡ Philosophy: Learn from failures to prevent future mistakes")
        print("   'Failure is the teacher, success is the test'\n")
        
        learner = run_learning_analysis()
        
        if learner:
            print(f"\nğŸ“ Results saved to: learning_insights.json")
            print("\nğŸš€ Try these commands:")
            print("   python failure_learner.py --analyze")
            print("   python failure_learner.py --benchmark")
        
        return
    
    # æ˜¾ç¤ºå¸®åŠ©
    parser.print_help()


if __name__ == "__main__":
    main()
