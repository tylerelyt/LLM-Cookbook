#!/usr/bin/env python3
"""
Lesson 4: åæ€æ”¹è¿›ç³»ç»Ÿæ¼”ç¤º

å±•ç¤ºå¦‚ä½•æ„å»ºåŸºäºåæ€çš„å†…å®¹æ”¹è¿›ç³»ç»Ÿï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œå®ç°ï¼š
1. å†…å®¹ç”Ÿæˆå’Œè´¨é‡åˆ†æ
2. ç³»ç»Ÿæ€§å‘ç°é—æ¼ç‚¹
3. åŸºäºåæ€çš„å†…å®¹æ”¹è¿›
4. é•¿æœŸè®°å¿†å’Œç»éªŒç§¯ç´¯

åŸºäº AutoGen çš„çœŸå®å®ç°ï¼Œæ”¯æŒè¯­ä¹‰æ£€ç´¢çš„é—æ¼ç‚¹è®°å¿†ç³»ç»Ÿã€‚
"""

import argparse
import json
import os
import re
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import numpy as np
from autogen import AssistantAgent, UserProxyAgent

# ==================== é…ç½®éƒ¨åˆ† ====================
def get_llm_config():
    """è·å– LLM é…ç½®"""
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
    
    model = os.getenv("LLM_MODEL", "qwen-max")
    return {
        "config_list": [{
            "model": model,
            "api_key": api_key,
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        }],
        "temperature": 0.7,
    }

# ==================== é—æ¼ç‚¹è®°å¿†ç³»ç»Ÿ ====================
class OmissionMemory:
    """é—æ¼ç‚¹é•¿æœŸè®°å¿†ç³»ç»Ÿï¼ˆæ‰å¹³å­˜å‚¨ï¼‰ã€‚

    - æŒä¹…åŒ–åˆ°è„šæœ¬åŒç›®å½• JSON æ–‡ä»¶ `reflection_memory.json`
    - ä»…è¯­ä¹‰æ£€ç´¢ï¼ˆDashScope å…¼å®¹ OpenAI æ¥å£ï¼‰ã€‚ä¸å¯ç”¨åˆ™ä¸æ£€ç´¢ï¼ˆè¿”å›ç©ºï¼‰
    - å­˜å‚¨ç»“æ„ä¸ºæ‰å¹³åˆ—è¡¨ï¼šæ¯æ¡ä¸ºä¸€ä¸ªåæ€æ¡ç›®ï¼ˆä¸å†æŒ‰é¢†åŸŸåˆ†å±‚ï¼‰ã€‚
    """

    def __init__(self, memory_file: str = None) -> None:
        # å°†æŒä¹…åŒ–æ–‡ä»¶å›ºå®šåœ¨è„šæœ¬ç›®å½•ï¼Œé¿å…å·¥ä½œç›®å½•å˜åŒ–å¯¼è‡´ä¸¢å¤±
        default_path = os.path.join(os.path.dirname(__file__), "reflection_memory.json")
        self.memory_file = memory_file or default_path
        self.entries: List[Dict] = []
        self.embeddings: Dict[str, np.ndarray] = {}
        self._embedding_client = self._init_embedding_client()
        self.load_memory()

    def _init_embedding_client(self):
        try:
            import openai  # type: ignore

            api_key = os.getenv("DASHSCOPE_API_KEY")
            if not api_key:
                return None

            # ä½¿ç”¨ DashScope å…¼å®¹æ¨¡å¼
            client = openai.OpenAI(
                api_key=api_key,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            )
            return client
        except Exception:
            return None

    def _get_embedding(self, text: str) -> Optional[np.ndarray]:
        if not self._embedding_client:
            return None
        try:
            resp = self._embedding_client.embeddings.create(
                model="text-embedding-v1", input=text
            )
            return np.array(resp.data[0].embedding)
        except Exception:
            return None

    def _text_for_embedding(self, item: Dict) -> str:
        parts = [
            item.get("domain", ""),
            item.get("type", ""),
            item.get("description", ""),
            item.get("suggestion", ""),
        ]
        return " ".join([p for p in parts if p])

    def add_omissions(self, domain: str, omissions: List[Dict]) -> None:
        for omission in omissions:
            entry = {
                "id": str(uuid.uuid4()),
                "timestamp": datetime.now().isoformat(),
                "domain": domain,
                "type": omission.get("type", ""),
                "description": omission.get("description", ""),
                "suggestion": omission.get("suggestion", ""),
            }
            self.entries.append(entry)

            emb_text = self._text_for_embedding(entry)
            emb = self._get_embedding(emb_text)
            if emb is not None:
                self.embeddings[entry["id"]] = emb

        self.save_memory()
        print(f"ğŸ’¾ å·²ä¿å­˜ {len(omissions)} ä¸ªé—æ¼ç‚¹åˆ°é¢†åŸŸï¼š{domain}")

    def get_relevant_omissions(self, query: str, limit: int = 3) -> List[Dict]:
        if not self.entries:
            return []

        # ä»…è¯­ä¹‰å¬å›ï¼ˆè‹¥ embeddings ç¼ºå¤±åˆ™æ‡’åŠ è½½è®¡ç®—ï¼‰
        query_emb = self._get_embedding(query)
        if query_emb is None:
            return []

        scored: List[Tuple[float, Dict]] = []
        for item in self.entries:
            emb = self.embeddings.get(item["id"])  # type: ignore[index]
            if emb is None:
                # æ‡’åŠ è½½ä¸ºè¯¥æ¡è®°å¿†ç”ŸæˆåµŒå…¥
                text = self._text_for_embedding(item)
                emb = self._get_embedding(text)
                if emb is None:
                    continue
                self.embeddings[item["id"]] = emb  # type: ignore[index]
            sim = float(np.dot(query_emb, emb) / (np.linalg.norm(query_emb) * np.linalg.norm(emb)))
            scored.append((sim, item))
        scored.sort(key=lambda x: x[0], reverse=True)
        return [item for _, item in scored[:limit]]

    def save_memory(self) -> None:
        try:
            with open(self.memory_file, "w", encoding="utf-8") as f:
                json.dump(self.entries, f, ensure_ascii=False, indent=2)
        except Exception:
            pass

    def load_memory(self) -> None:
        if not os.path.exists(self.memory_file):
            return
        try:
            with open(self.memory_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            # æ–°ç‰ˆä»…æ”¯æŒæ‰å¹³åˆ—è¡¨
            self.entries = data if isinstance(data, list) else []
        except Exception:
            self.entries = []

# å…¨å±€è®°å¿†ç³»ç»Ÿå®ä¾‹
memory = OmissionMemory()

# ==================== åæ€æ¶ˆæ¯å¤„ç† ====================
def _reflection_message(recipient, messages, sender, config):
    content = recipient.chat_messages_for_summary(sender)[-1]["content"]

    # åœ¨åæ€å‰æ£€ç´¢ç›¸å…³å†å²åæ€ï¼Œä½œä¸ºä¸Šä¸‹æ–‡æç¤º
    relevant = memory.get_relevant_omissions(content)
    hints = ""
    if relevant:
        lines = [f"â€¢ {it.get('description', '')}ï¼ˆå»ºè®®ï¼š{it.get('suggestion', '')}ï¼‰" for it in relevant]
        hints = "\nå†å²é—æ¼ç‚¹å‚è€ƒ:\n" + "\n".join(lines)

    return f"""è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„é—æ¼ç‚¹ï¼š

{content}
{hints}

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºé—æ¼ç‚¹åˆ†æï¼š
```json
{{
  "domain": "å†…å®¹ä¸»é¢˜é¢†åŸŸï¼ˆè‡ªåŠ¨è¯†åˆ«ï¼‰",
  "omissions": [
    {{
      "type": "é—æ¼ç±»å‹",
      "description": "å…·ä½“é—æ¼æè¿°",
      "suggestion": "æ”¹è¿›å»ºè®®"
    }}
  ]
}}
```"""

def _extract_omissions_from_reflection(reflection_text: str) -> Tuple[str, List[Dict]]:
    try:
        match = re.search(r"```json\s*(\{.*?\})\s*```", reflection_text, re.DOTALL)
        if not match:
            return "é€šç”¨", []
        data = json.loads(match.group(1))
        domain = data.get("domain", "é€šç”¨")
        omissions = data.get("omissions", [])
        if isinstance(omissions, list):
            return domain, omissions
        return domain, []
    except Exception:
        return "é€šç”¨", []

# ==================== æ™ºèƒ½ä½“åˆ›å»º ====================
def create_actor():
    """åˆ›å»ºActoræ™ºèƒ½ä½“ - è´Ÿè´£å†…å®¹ç”Ÿæˆå’Œè¡ŒåŠ¨æ‰§è¡Œ"""
    llm_config = get_llm_config()
    
    return AssistantAgent(
        name="Actor",
        system_message="""ä½ æ˜¯å†…å®¹åˆ›ä½œä¸“å®¶ï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆé«˜è´¨é‡å†…å®¹ã€‚

è¯·æ ¹æ®è¦æ±‚åˆ›ä½œå†…å®¹ï¼ŒåŠ›æ±‚å…¨é¢å’Œæ·±å…¥ã€‚""",
        llm_config=llm_config,
    )

def create_evaluator():
    """åˆ›å»ºEvaluatoræ™ºèƒ½ä½“ - è´Ÿè´£è¯„ä¼°å†…å®¹è´¨é‡"""
    llm_config = get_llm_config()
    
    return AssistantAgent(
        name="Evaluator",
        system_message="""ä½ æ˜¯å†…å®¹è´¨é‡è¯„ä¼°ä¸“å®¶ï¼Œè´Ÿè´£è¯„ä¼°å†…å®¹çš„å„ä¸ªæ–¹é¢ã€‚

è¯·å®¢è§‚è¯„ä¼°å†…å®¹è´¨é‡ï¼Œæä¾›è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šã€‚""",
        llm_config=llm_config,
    )

def create_self_reflection():
    """åˆ›å»ºSelf-reflectionæ™ºèƒ½ä½“ - è´Ÿè´£æ·±åº¦åæ€å’Œå­¦ä¹ """
    llm_config = get_llm_config()
    
    return AssistantAgent(
        name="Self-reflection",
        system_message="""ä½ æ˜¯æ·±åº¦åæ€ä¸“å®¶ï¼Œè´Ÿè´£åŸºäºè¯„ä¼°ç»“æœè¿›è¡Œæ·±åº¦åæ€å’Œå­¦ä¹ ã€‚

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºåæ€ç»“æœï¼š
```json
{
    "domain": "å†…å®¹ä¸»é¢˜é¢†åŸŸ",
    "omissions": [
        {
            "type": "é—æ¼ç±»å‹",
            "description": "å…·ä½“é—æ¼æè¿°",
            "suggestion": "æ”¹è¿›å»ºè®®"
        }
    ],
    "lessons_learned": ["ç»éªŒæ•™è®­1", "ç»éªŒæ•™è®­2"],
    "improvement_plan": "å…·ä½“çš„æ”¹è¿›è®¡åˆ’"
}
```""",
        llm_config=llm_config,
    )

def create_user_proxy():
    """åˆ›å»ºç”¨æˆ·ä»£ç†"""
    return UserProxyAgent(
        name="ç”¨æˆ·",
        human_input_mode="NEVER",
        max_consecutive_auto_reply=2,
        is_termination_msg=lambda msg: "æ”¹è¿›å®Œæˆ" in msg.get("content", "").lower(),
        code_execution_config={"use_docker": False},
    )

# ==================== åæ€æ”¹è¿›æµç¨‹ ====================
class ReflectionSystem:
    """åæ€æ”¹è¿›ç³»ç»Ÿ - åŸºäºæ ‡å‡†åæ€å­¦ä¹ æ¶æ„"""
    
    def __init__(self):
        # æŒ‰ç…§åæ€å­¦ä¹ æ¶æ„åˆ›å»ºæ™ºèƒ½ä½“
        self.actor = create_actor()           # Actor: è´Ÿè´£å†…å®¹ç”Ÿæˆå’Œè¡ŒåŠ¨æ‰§è¡Œ
        self.evaluator = create_evaluator()   # Evaluator: è´Ÿè´£è¯„ä¼°å†…å®¹è´¨é‡
        self.self_reflection = create_self_reflection()  # Self-reflection: è´Ÿè´£æ·±åº¦åæ€
        self.user_proxy = create_user_proxy()  # ç”¨æˆ·ä»£ç†ï¼šåè°ƒæ•´ä¸ªæµç¨‹
    
    def generate_with_reflection(self, task: str) -> Dict:
        """å®Œæ•´çš„åæ€æ”¹è¿›æµç¨‹"""
        print(f"\nğŸ¯ å¼€å§‹åæ€æ”¹è¿›æµç¨‹")
        print("="*60)
        
        # ç¬¬ä¸€æ­¥ï¼šæ£€ç´¢å†å²ç»éªŒå¹¶åŠ è½½åˆ°Actor
        print("\nğŸ“š æ­¥éª¤1: åŠ è½½å†å²åæ€ç»éªŒ...")
        historical_experience = memory.get_relevant_omissions(task)
        
        experience_context = ""
        if historical_experience:
            print(f"æ‰¾åˆ° {len(historical_experience)} æ¡ç›¸å…³ç»éªŒ")
            experience_context = "\n\nğŸ“– å†å²åæ€ç»éªŒå‚è€ƒï¼š\n"
            for exp in historical_experience:
                experience_context += f"- ä¸»é¢˜: {exp.get('domain', 'N/A')}\n"
                experience_context += f"  ğŸ’¡ {exp.get('description', 'N/A')}ï¼ˆå»ºè®®ï¼š{exp.get('suggestion', 'N/A')}ï¼‰\n"
        else:
            print("æœªæ‰¾åˆ°ç›¸å…³å†å²ç»éªŒï¼Œè¿›è¡Œé¦–æ¬¡æ¢ç´¢")
        
        # ç¬¬äºŒæ­¥ï¼šActorç”Ÿæˆåˆå§‹å†…å®¹ï¼ˆå·²åŠ è½½å†å²ç»éªŒï¼‰
        print("\nğŸ­ æ­¥éª¤2: Actorç”Ÿæˆåˆå§‹å†…å®¹...")
        generation_prompt = f"""è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

{task}

{experience_context}

è¯·åˆ›ä½œç»“æ„å®Œæ•´ã€å†…å®¹ä¸°å¯Œçš„å›ç­”ã€‚"""
        
        self.user_proxy.initiate_chat(
            self.actor,
            message=generation_prompt,
            max_turns=2
        )
        
        # è·å–ç”Ÿæˆçš„å†…å®¹
        generated_content = self._extract_content_from_chat()
        print(f"âœ… åˆå§‹å†…å®¹ç”Ÿæˆå®Œæˆ ({len(generated_content)} å­—ç¬¦)")
        
        # ç¬¬ä¸‰æ­¥ï¼šEvaluatorè¯„ä¼°å†…å®¹è´¨é‡
        print("\nğŸ“Š æ­¥éª¤3: Evaluatorè¯„ä¼°å†…å®¹è´¨é‡...")
        evaluation_prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹å†…å®¹çš„è´¨é‡ï¼š

ä»»åŠ¡ï¼š{task}

å†…å®¹ï¼š
{generated_content}

è¯·ä»å®Œæ•´æ€§ã€é€»è¾‘æ€§ã€å®ç”¨æ€§ã€å‰ç»æ€§ã€å—ä¼—é€‚é…ç­‰ç»´åº¦è¿›è¡Œå…¨é¢è¯„ä¼°ã€‚"""
        
        self.user_proxy.initiate_chat(
            self.evaluator,
            message=evaluation_prompt,
            max_turns=2
        )
        
        # è·å–è¯„ä¼°ç»“æœ
        evaluation_result = self._extract_content_from_chat()
        print("âœ… å†…å®¹è¯„ä¼°å®Œæˆ")
        
        # ç¬¬å››æ­¥ï¼šSelf-reflectionæ·±åº¦åæ€
        print("\nğŸ§  æ­¥éª¤4: Self-reflectionæ·±åº¦åæ€...")
        reflection_prompt = f"""åŸºäºè¯„ä¼°ç»“æœï¼Œè¯·è¿›è¡Œæ·±åº¦åæ€ï¼š

åŸå§‹å†…å®¹ï¼š
{generated_content}

è¯„ä¼°ç»“æœï¼š
{evaluation_result}

è¯·æ·±å…¥åˆ†æå†…å®¹ä¸­çš„é—®é¢˜å’Œä¸è¶³ï¼Œæå–ç»éªŒæ•™è®­ï¼Œå¹¶æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚"""
        
        self.user_proxy.initiate_chat(
            self.self_reflection,
            message=reflection_prompt,
            max_turns=2
        )
        
        # è§£æåæ€ç»“æœ
        reflection_result = self._extract_analysis_from_chat()
        print("âœ… æ·±åº¦åæ€å®Œæˆ")
        
        # ç¬¬äº”æ­¥ï¼šåŸºäºåæ€ç»“æœæ”¹è¿›å†…å®¹
        if reflection_result.get("omissions"):
            print(f"\nğŸ”„ æ­¥éª¤5: åŸºäºåæ€ç»“æœæ”¹è¿›å†…å®¹ (å‘ç° {len(reflection_result['omissions'])} ä¸ªæ”¹è¿›ç‚¹)...")
            
            improvement_prompt = f"""åŸºäºåæ€ç»“æœï¼Œè¯·é‡æ–°ä¼˜åŒ–å†…å®¹ï¼š

åŸå§‹å†…å®¹ï¼š
{generated_content}

åæ€ç»“æœï¼š
{json.dumps(reflection_result, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆæ”¹è¿›åçš„å®Œæ•´å†…å®¹ï¼Œç¡®ä¿è§£å†³åæ€ä¸­å‘ç°çš„é—æ¼ç‚¹ã€‚"""
            
            self.user_proxy.initiate_chat(
                self.actor,
                message=improvement_prompt,
                max_turns=2
            )
            
            improved_content = self._extract_content_from_chat()
            print("âœ… å†…å®¹æ”¹è¿›å®Œæˆ")
        else:
            print("\nâœ… å†…å®¹è´¨é‡è‰¯å¥½ï¼Œæ— éœ€æ”¹è¿›")
            improved_content = generated_content
        
        # ç¬¬å…­æ­¥ï¼šä¿å­˜åæ€ç»éªŒåˆ°é•¿æœŸè®°å¿†
        print("\nğŸ’¾ æ­¥éª¤6: ä¿å­˜åæ€ç»éªŒåˆ°é•¿æœŸè®°å¿†...")
        if reflection_result.get("omissions"):
            # è½¬æ¢æ ¼å¼ä»¥é€‚é…è®°å¿†ç³»ç»Ÿ
            omissions_for_memory = []
            for omission in reflection_result["omissions"]:
                omissions_for_memory.append({
                    "type": omission.get("type", "é€šç”¨"),
                    "description": omission.get("description", ""),
                    "suggestion": omission.get("suggestion", "")
                })
            # ä½¿ç”¨ä»»åŠ¡å†…å®¹çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºdomain
            domain = task[:50] + "..." if len(task) > 50 else task
            memory.add_omissions(domain, omissions_for_memory)
            print(f"âœ… å·²ä¿å­˜ {len(omissions_for_memory)} ä¸ªé—æ¼ç‚¹åˆ°é•¿æœŸè®°å¿†")
        else:
            print("â„¹ï¸ æœªå‘ç°é—æ¼ç‚¹ï¼Œæ— éœ€ä¿å­˜")
        
        # è¿”å›ç»“æœ
        result = {
            "task": task,
            "original_content": generated_content,
            "improved_content": improved_content,
            "evaluation": evaluation_result,
            "reflection": reflection_result,
            "improvement_applied": len(reflection_result.get("omissions", [])) > 0
        }
        
        print("\nğŸ‰ åæ€æ”¹è¿›æµç¨‹å®Œæˆï¼")
        return result
    
    def _extract_content_from_chat(self) -> str:
        """ä»å¯¹è¯ä¸­æå–å†…å®¹"""
        try:
            # è·å–æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯
            if hasattr(self.user_proxy, 'chat_messages'):
                for agent_name, messages in self.user_proxy.chat_messages.items():
                    if messages and agent_name != "ç”¨æˆ·":
                        last_message = messages[-1]
                        if isinstance(last_message, dict):
                            return last_message.get("content", "")
                        else:
                            return str(last_message)
            return "å†…å®¹æå–å¤±è´¥"
        except Exception as e:
            print(f"âš ï¸ å†…å®¹æå–é”™è¯¯: {e}")
            return "å†…å®¹æå–å¤±è´¥"
    
    def _extract_analysis_from_chat(self) -> Dict:
        """ä»å¯¹è¯ä¸­æå–åˆ†æç»“æœ"""
        try:
            # ä¸“é—¨ä»Self-reflectionçš„æ¶ˆæ¯ä¸­æå–å†…å®¹
            if hasattr(self.user_proxy, 'chat_messages') and "Self-reflection" in self.user_proxy.chat_messages:
                messages = self.user_proxy.chat_messages["Self-reflection"]
                if messages:
                    content = messages[-1].get("content", "") if isinstance(messages[-1], dict) else str(messages[-1])
                    print(f"ğŸ” æå–çš„åæ€å†…å®¹: {content[:200]}...")
                    
                    # å°è¯•ä»å†…å®¹ä¸­æå–JSON
                    import re
                    json_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(1)
                        print(f"ğŸ“‹ æ‰¾åˆ°JSONå†…å®¹: {json_str[:100]}...")
                        result = json.loads(json_str)
                        print(f"âœ… JSONè§£ææˆåŠŸï¼Œé—æ¼ç‚¹æ•°é‡: {len(result.get('omissions', []))}")
                        return result
                    else:
                        print("âš ï¸ æœªæ‰¾åˆ°JSONæ ¼å¼çš„åæ€ç»“æœ")
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œåˆ›å»ºåŸºæœ¬çš„ç»“æ„
                        return {
                            "domain": "é€šç”¨",
                            "omissions": [],
                            "lessons_learned": [],
                            "improvement_plan": ""
                        }
            else:
                print("âš ï¸ æœªæ‰¾åˆ°Self-reflectionçš„æ¶ˆæ¯")
                # å°è¯•ä»æ‰€æœ‰æ¶ˆæ¯ä¸­æŸ¥æ‰¾åŒ…å«JSONçš„å†…å®¹
                if hasattr(self.user_proxy, 'chat_messages'):
                    for agent_name, messages in self.user_proxy.chat_messages.items():
                        for msg in messages[::-1]:  # ä»æœ€æ–°çš„æ¶ˆæ¯å¼€å§‹æŸ¥æ‰¾
                            content = msg.get("content", "") if isinstance(msg, dict) else str(msg)
                            if "```json" in content:
                                print(f"ğŸ” åœ¨ {agent_name} çš„æ¶ˆæ¯ä¸­æ‰¾åˆ°JSONå†…å®¹")
                                import re
                                json_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
                                if json_match:
                                    json_str = json_match.group(1)
                                    print(f"ğŸ“‹ æ‰¾åˆ°JSONå†…å®¹: {json_str[:100]}...")
                                    result = json.loads(json_str)
                                    print(f"âœ… JSONè§£ææˆåŠŸï¼Œé—æ¼ç‚¹æ•°é‡: {len(result.get('omissions', []))}")
                                    return result
                
                return {
                    "domain": "é€šç”¨",
                    "omissions": [],
                    "lessons_learned": [],
                    "improvement_plan": ""
                }
        except Exception as e:
            print(f"âš ï¸ åæ€ç»“æœè§£æé”™è¯¯: {e}")
            return {"domain": "é€šç”¨", "omissions": []}
    




# ==================== æ¼”ç¤ºåœºæ™¯ ====================
def demo_content_improvement():
    """æ¼”ç¤ºå†…å®¹æ”¹è¿›æµç¨‹"""
    print("\nğŸ“ === å†…å®¹æ”¹è¿›æ¼”ç¤º ===")
    
    system = ReflectionSystem()
    
    # æµ‹è¯•ä»»åŠ¡å®šä¹‰ - ä»…åœ¨è¿™é‡Œå®šä¹‰ï¼Œä¸ç»‘å®šåˆ°é€šç”¨å®ç°
    task = """è®¾è®¡ä¸€ä¸ªç»“åˆä¸‰å›½æ€å’Œç‹¼äººæ€è§„åˆ™çš„æ¡Œæ¸¸ï¼Œè¦æ±‚ï¼š
- 800å­—å·¦å³çš„è®¾è®¡æ–¹æ¡ˆ
- åŒ…å«æ¸¸æˆèƒŒæ™¯è®¾å®šå’Œè§’è‰²è®¾è®¡
- è¯¦ç»†è¯´æ˜æ¸¸æˆè§„åˆ™å’Œæµç¨‹
- åˆ†ææ¸¸æˆå¹³è¡¡æ€§å’Œå¯ç©æ€§
- æä¾›å…·ä½“çš„æ¸¸æˆé…ä»¶æ¸…å•
- è€ƒè™‘ä¸åŒç©å®¶æ•°é‡çš„é€‚é…æ€§"""
    
    try:
        result = system.generate_with_reflection(task)
        
        print("\nğŸ“Š === æ”¹è¿›æ•ˆæœå¯¹æ¯” ===")
        print(f"åŸå§‹å†…å®¹é•¿åº¦: {len(result['original_content'])} å­—ç¬¦")
        print(f"æ”¹è¿›å†…å®¹é•¿åº¦: {len(result['improved_content'])} å­—ç¬¦")
        print(f"æ˜¯å¦è¿›è¡Œäº†æ”¹è¿›: {'æ˜¯' if result['improvement_applied'] else 'å¦'}")
        
        if result["reflection"].get("omissions"):
            print(f"å‘ç°çš„é—æ¼ç‚¹æ•°é‡: {len(result['reflection']['omissions'])}")
            for i, omission in enumerate(result["reflection"]["omissions"], 1):
                print(f"  {i}. {omission.get('description', 'N/A')}")
        
        return result
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå‡ºç°é”™è¯¯: {e}")
        return None



# ==================== ä¸»ç¨‹åº ====================
def main():
    """ä¸»æ¼”ç¤ºç¨‹åº"""
    print("ğŸ§  === AutoGen åæ€æ”¹è¿›ç³»ç»Ÿæ¼”ç¤º ===")
    print("å±•ç¤ºåŸºäºåæ€çš„å†…å®¹è´¨é‡æŒç»­ä¼˜åŒ–æœºåˆ¶")
    print("="*60)
    
    # ç¯å¢ƒæ£€æŸ¥
    try:
        llm_config = get_llm_config()
        print("âœ… LLM é…ç½®æ£€æŸ¥é€šè¿‡")
    except ValueError as e:
        print(f"âŒ {e}")
        return
    
    print(f"\nğŸ“š å½“å‰åæ€è®°å¿†: {len(memory.entries)} æ¡å†å²è®°å½•")
    
    try:
        # å®Œæ•´æµç¨‹æ¼”ç¤º
        demo_content_improvement()
        
        print("\n" + "="*60)
        print("ğŸ‰ === åæ€æ”¹è¿›ç³»ç»Ÿæ¼”ç¤ºå®Œæˆ ===")
        
        print("\nğŸ“Š === ç³»ç»Ÿèƒ½åŠ›æ€»ç»“ ===")
        print("âœ… **é—æ¼è¯†åˆ«**: ç³»ç»Ÿæ€§å‘ç°å†…å®¹ä¸­çš„é—æ¼ç‚¹å’Œä¸è¶³")
        print("âœ… **è´¨é‡æ”¹è¿›**: åŸºäºåæ€ç»“æœè¿­ä»£ä¼˜åŒ–å†…å®¹è´¨é‡")
        print("âœ… **ç»éªŒç§¯ç´¯**: å†å²åæ€ç»éªŒæŒ‡å¯¼æœªæ¥å†…å®¹ç”Ÿæˆ")
        print("âœ… **å¤šæ™ºèƒ½ä½“åä½œ**: ä¸“ä¸šåˆ†å·¥æé«˜åˆ†æå’Œæ”¹è¿›è´¨é‡")
        print("âœ… **æŒç»­å­¦ä¹ **: åæ€ç³»ç»Ÿä¸æ–­å­¦ä¹ å’Œå®Œå–„")
        print("âœ… **è¯­ä¹‰æ£€ç´¢**: åŸºäºåµŒå…¥å‘é‡çš„æ™ºèƒ½è®°å¿†æ£€ç´¢")
        
        print("\nğŸ’¡ === å…³é”®ä»·å€¼ ===")
        print("â€¢ ç³»ç»Ÿæ€§æå‡å†…å®¹åˆ›ä½œè´¨é‡")
        print("â€¢ å»ºç«‹ç»„ç»‡çº§çš„å†…å®¹æ”¹è¿›çŸ¥è¯†åº“") 
        print("â€¢ å®ç°å†…å®¹åˆ›ä½œçš„æŒç»­ä¼˜åŒ–")
        print("â€¢ é™ä½å†…å®¹é—æ¼å’Œè´¨é‡é£é™©")
        print("â€¢ åŸ¹å…»åæ€æ€§æ€ç»´å’Œè´¨é‡æ„è¯†")
        
        print(f"\nğŸ“ åæ€è®°å¿†ä¿å­˜åœ¨: {memory.memory_file}")
        print(f"ğŸ“ˆ æ€»è®¡ç§¯ç´¯åæ€ç»éªŒ: {len(memory.entries)} æ¡")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

if __name__ == "__main__":
    main()
